# scripts/2clean_and_merge_v2.py
"""
åˆå¹¶å¹¶æ¸…æ´—75ä¸ªåœºæ™¯çš„æ•°æ®
âœ… æ”¯æŒ5å¯†åº¦é…ç½®
âœ… æµé‡éªŒè¯
"""
import sys
sys.path.append('D:/Carla Simulation')

import pandas as pd
import numpy as np
from pathlib import Path
from roundabout_config_v2 import *


def load_all_scenarios():
    """åŠ è½½æ‰€æœ‰åœºæ™¯æ•°æ®"""
    print(f"æ­£åœ¨åŠ è½½{TOTAL_SCENARIOS}ä¸ªåœºæ™¯...")

    all_data = []
    for i in range(TOTAL_SCENARIOS):
        file_path = Path(RAW_DATA_DIR) / f'scenario_{i:03d}.csv'
        if file_path.exists():
            df = pd.read_csv(file_path)
            df['scenario_id'] = i
            all_data.append(df)
            print(f"  âœ“ scenario_{i:03d}.csv: {len(df):,} è¡Œ, {df['trackId'].nunique()} è½¨è¿¹")
        else:
            print(f"  âœ— scenario_{i:03d}.csv: æœªæ‰¾åˆ°")

    if not all_data:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶")
        return None

    merged = pd.concat(all_data, ignore_index=True)
    print(f"\nâœ… åŠ è½½å®Œæˆ: {len(merged):,} è¡Œ")

    return merged


def verify_flow_rates(df):
    """éªŒè¯æµé‡æ˜¯å¦ç¬¦åˆç›®æ ‡"""
    print("\n" + "=" * 80)
    print("æµé‡éªŒè¯ (åŸºäºHCM 2010ç›®æ ‡)")
    print("=" * 80)
    
    print(f"\næ ¸å¿ƒåŒºå®šä¹‰: åŠå¾„ â‰¤ 25ç±³")
    print(f"éªŒè¯æ ‡å‡†: å®é™…é€šè¿‡è½¦è¾†æ•° â‰ˆ ç›®æ ‡å€¼ Â± 20%")
    
    results = []
    
    for scenario_id in sorted(df['scenario_id'].unique()):
        scenario_data = df[df['scenario_id'] == scenario_id]
        
        density = scenario_data['traffic_density'].iloc[0]
        weather = scenario_data['weather'].iloc[0]
        behavior = scenario_data['behavior_type'].iloc[0]
        
        # ç»Ÿè®¡æ ¸å¿ƒåŒºè½¨è¿¹
        core_data = scenario_data[scenario_data['radius'] <= 25]
        core_tracks = core_data['trackId'].nunique()
        
        # è·å–ç›®æ ‡å€¼
        target = TRAFFIC_DENSITIES[density]['target_passages']
        
        # è®¡ç®—åå·®
        deviation = (core_tracks - target) / target * 100 if target > 0 else 0
        status = "âœ…" if abs(deviation) <= 20 else "âš ï¸"
        
        results.append({
            'scenario_id': scenario_id,
            'weather': weather,
            'density': density,
            'behavior': behavior,
            'target': target,
            'actual': core_tracks,
            'deviation': deviation,
            'status': status
        })
    
    results_df = pd.DataFrame(results)
    
    # æ‰“å°ç»“æœ
    print(f"\n{'åœºæ™¯ID':<8} {'å¯†åº¦':<12} {'è¡Œä¸º':<12} {'ç›®æ ‡':<6} {'å®é™…':<6} {'åå·®':<8} {'çŠ¶æ€'}")
    print("-" * 80)
    
    for _, row in results_df.iterrows():
        print(f"{row['scenario_id']:>6}   {row['density']:<12} {row['behavior']:<12} "
              f"{row['target']:>4}   {row['actual']:>4}   {row['deviation']:>+6.1f}%  {row['status']}")
    
    # æŒ‰å¯†åº¦ç»Ÿè®¡
    print("\n" + "=" * 80)
    print("æŒ‰å¯†åº¦ç»Ÿè®¡")
    print("=" * 80)
    
    for density in TRAFFIC_DENSITIES.keys():
        density_results = results_df[results_df['density'] == density]
        if len(density_results) == 0:
            continue
            
        target = TRAFFIC_DENSITIES[density]['target_passages']
        avg_actual = density_results['actual'].mean()
        qualified = (density_results['deviation'].abs() <= 20).sum()
        total = len(density_results)
        flow = TRAFFIC_DENSITIES[density]['target_flow']
        
        print(f"\n{density.upper()}:")
        print(f"  ç›®æ ‡æµé‡: {flow} veh/h")
        print(f"  ç›®æ ‡é€šè¿‡: {target}è¾†/åœºæ™¯")
        print(f"  å®é™…å¹³å‡: {avg_actual:.1f}è¾†/åœºæ™¯")
        print(f"  åˆæ ¼ç‡: {qualified}/{total} ({qualified/total*100:.1f}%)")
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = Path(PROCESSED_DATA_DIR) / 'flow_validation_report.csv'
    Path(PROCESSED_DATA_DIR).mkdir(parents=True, exist_ok=True)
    results_df.to_csv(report_file, index=False)
    print(f"\nâœ… éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    return results_df


def clean_data(df):
    """æ¸…æ´—æ•°æ®"""
    print("\n" + "=" * 80)
    print("æ•°æ®æ¸…æ´—")
    print("=" * 80)

    original_rows = len(df)
    original_tracks = df['trackId'].nunique()

    print(f"\nåŸå§‹æ•°æ®: {original_rows:,} è¡Œ, {original_tracks} æ¡è½¨è¿¹")

    # 1. è¿‡æ»¤èŒƒå›´å¤–æ•°æ®
    print(f"\n[1/5] è¿‡æ»¤èŒƒå›´å¤–æ•°æ® (>{COLLECTION_RADIUS}ç±³)...")
    df_filtered = df[df['radius'] <= COLLECTION_RADIUS].copy()
    removed = original_rows - len(df_filtered)
    print(f"  ç§»é™¤ {removed:,} è¡Œ ({removed / original_rows * 100:.1f}%)")

    # 2-3. è¿‡æ»¤çŸ­è½¨è¿¹
    print(f"\n[2/5] è¿‡æ»¤çŸ­è½¨è¿¹ (<2ç§’)...")
    min_length = 20
    track_lengths = df_filtered.groupby('trackId').size()
    valid_tracks = track_lengths[track_lengths >= min_length].index
    df_filtered = df_filtered[df_filtered['trackId'].isin(valid_tracks)]
    removed_tracks = original_tracks - len(valid_tracks)
    print(f"  ç§»é™¤ {removed_tracks} æ¡è½¨è¿¹")

    # 4. è¿‡æ»¤é™æ­¢è½¦è¾†
    print(f"\n[3/5] è¿‡æ»¤é™æ­¢è½¦è¾† (å¹³å‡é€Ÿåº¦<0.5m/s)...")
    track_speeds = df_filtered.groupby('trackId')['speed'].mean()
    moving_tracks = track_speeds[track_speeds >= 0.5].index
    df_filtered = df_filtered[df_filtered['trackId'].isin(moving_tracks)]
    removed_static = len(valid_tracks) - len(moving_tracks)
    print(f"  ç§»é™¤ {removed_static} æ¡é™æ­¢è½¨è¿¹")

    # 5. é‡æ–°åˆ†é…å…¨å±€trackId
    print(f"\n[4/5] é‡æ–°åˆ†é…å…¨å±€trackId...")
    df_filtered['original_trackId'] = df_filtered['trackId']
    df_filtered['global_trackId'] = (
        df_filtered['scenario_id'].astype(str) + '_' +
        df_filtered['trackId'].astype(str)
    )
    track_mapping = {track: idx for idx, track in enumerate(df_filtered['global_trackId'].unique())}
    df_filtered['trackId'] = df_filtered['global_trackId'].map(track_mapping)
    df_filtered = df_filtered.drop(columns=['global_trackId'])

    final_rows = len(df_filtered)
    final_tracks = df_filtered['trackId'].nunique()

    print("\n" + "=" * 80)
    print("æ¸…æ´—ç»“æœ")
    print("=" * 80)
    print(f"\næ•°æ®è¡Œæ•°: {original_rows:,} â†’ {final_rows:,} (ä¿ç•™{final_rows/original_rows*100:.1f}%)")
    print(f"è½¨è¿¹æ•°é‡: {original_tracks} â†’ {final_tracks} (ä¿ç•™{final_tracks/original_tracks*100:.1f}%)")

    return df_filtered


def analyze_data(df):
    """åˆ†ææ¸…æ´—åçš„æ•°æ®"""
    print("\n" + "=" * 80)
    print("æ•°æ®åˆ†æ")
    print("=" * 80)

    print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
    print(f"  æ€»è¡Œæ•°: {len(df):,}")
    print(f"  è½¨è¿¹æ•°: {df['trackId'].nunique()}")
    print(f"  åœºæ™¯æ•°: {df['scenario_id'].nunique()}")

    print(f"\nğŸ“ˆ è¿åŠ¨ç»Ÿè®¡:")
    print(f"  é€Ÿåº¦: {df['speed'].mean():.2f} m/s ({df['speed'].mean()*3.6:.1f} km/h)")
    print(f"  åŠå¾„: {df['radius'].mean():.2f} m")

    print(f"\nğŸŒ¦ï¸ å¤©æ°”åˆ†å¸ƒ:")
    for weather in sorted(df['weather'].unique()):
        count = len(df[df['weather'] == weather])
        tracks = df[df['weather'] == weather]['trackId'].nunique()
        print(f"  {weather:20s}: {count:7,} è¡Œ, {tracks:4} è½¨è¿¹")

    print(f"\nğŸš— å¯†åº¦åˆ†å¸ƒ:")
    for density in TRAFFIC_DENSITIES.keys():
        if density in df['traffic_density'].values:
            count = len(df[df['traffic_density'] == density])
            tracks = df[df['traffic_density'] == density]['trackId'].nunique()
            print(f"  {density:12s}: {count:7,} è¡Œ, {tracks:4} è½¨è¿¹")

    print(f"\nğŸ¯ è¡Œä¸ºåˆ†å¸ƒ:")
    for behavior in sorted(df['behavior_type'].unique()):
        count = len(df[df['behavior_type'] == behavior])
        tracks = df[df['behavior_type'] == behavior]['trackId'].nunique()
        avg_speed = df[df['behavior_type'] == behavior]['speed'].mean()
        print(f"  {behavior:10s}: {count:7,} è¡Œ, {tracks:4} è½¨è¿¹, {avg_speed:.2f} m/s")


def main():
    print("=" * 80)
    print("æ•°æ®åˆå¹¶ã€æ¸…æ´—ä¸éªŒè¯ - v2")
    print("=" * 80)

    Path(PROCESSED_DATA_DIR).mkdir(parents=True, exist_ok=True)

    # 1. åŠ è½½æ•°æ®
    df_raw = load_all_scenarios()
    if df_raw is None:
        return

    # 2. éªŒè¯æµé‡
    flow_report = verify_flow_rates(df_raw)

    # 3. æ¸…æ´—æ•°æ®
    df_clean = clean_data(df_raw)

    # 4. åˆ†ææ•°æ®
    analyze_data(df_clean)

    # 5. ä¿å­˜
    output_file = Path(PROCESSED_DATA_DIR) / 'carla_round_all.csv'
    df_clean.to_csv(output_file, index=False)

    print("\n" + "=" * 80)
    print("âœ… ä¿å­˜å®Œæˆ")
    print("=" * 80)
    print(f"\næ–‡ä»¶: {output_file}")
    print(f"å¤§å°: {output_file.stat().st_size / 1024 / 1024:.1f} MB")

    print("\nä¸‹ä¸€æ­¥: è¿è¡Œ 3split_dataset_v2.py åˆ’åˆ†æ•°æ®é›†")


if __name__ == '__main__':
    main()
